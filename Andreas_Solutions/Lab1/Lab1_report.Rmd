---
title: "Lab1\nExamining multivariate data"
author: "Andreas C Charitos [andch552]"
date: "1/22/2021"
output: pdf_document
---

\tableofcontents

\newpage

```{r,,message=FALSE,echo=FALSE}
# Import libraries --------------------------------------------------------
library(ggplot2)
library(GGally)
library(reshape)
# library(kableExtra)
library(knitr)
library(dplyr)
library(plotly)
library(RColorBrewer)
library(aplpack)
```


# Problem 1

## Data Overview

Table of the first 3 lines of the data
--------------------------------------


```{r, echo=FALSE}
dt = read.delim("T1-9.dat", header=FALSE)

colnames(dt) = c('country', '100m', '200m', '400m', '800m', '1500m', '3000m','marathon')

kable(dt[1:3,],
      caption = "First 3 rows of the data")

```

## a)
Compute the means, the variances and the standard deviations for all variables.

 
Table of column means
---------------------

```{r,echo=F}
col_means = sapply(dt[, -1], mean)
kable(col_means,
       caption = "Column means")

```

Table of column variances
-------------------------

```{r,echo=F}
col_var = sapply(dt[, -1], var)

kable(col_var,
       caption = "Column variances")

```
  

Table of column standard deviations
-----------------------------------

```{r,echo=F}
col_sd = sapply(dt[, -1], sd)
kable(col_sd,
      caption = "Column standard deviations")

```


The tables above provide an overview of the column mean, variance and standard deviations for all the variables.

## b)

Illustrate the variables using box-plots and histograms. Do the variables look normally distributed? Justify your answer.

Histograms
----------


```{r,echo=F}
# Histograms
# Values for the normal distribution.

x = seq(-5, 5, 0.1)
y = dnorm(x)
par(mar=rep(2,4))
par(mfrow=c(4,2), bg='whitesmoke', mar=c(1.9,1.9,1.9,1.9))
for (i in 2:8){
  hist(scale(dt[, i]),
       freq=FALSE,
       breaks=10,
       main=paste('Histogram of variable', colnames(dt)[i]),
       col='gray',
       border='blue', panel.first = grid(25,25))
  lines(x, y, col='tomato4')
}
```

Boxplots
--------

```{r,echo=F}
# Boxplots
par(mar=rep(2,4))
par(mfrow=c(4,2), bg='whitesmoke', mar=c(1.9,1.9,1.9,1.9))
for(i in 2:9){
  if(i!=9){
  boxplot(dt[, i], horizontal = TRUE, 
          main = paste('Boxplot for variable', colnames(dt)[i]))
  # Add mean line
  segments(x0 = mean(dt[, i]), y0 = 0.8,
           x1 = mean(dt[, i]), y1 = 1.2,
           col = "red", lwd = 2)
  # Add mean point
  # points(mean(dt[, i]), 1, col = 3, pch = 19, cex=2)
  stripchart(dt[, i], method = "jitter", 
             pch = 19, add = TRUE, 
             col = "blue", cex =0.5)}else{
    par(mai=c(0,0,0,0))
    plot.new()
    legend('center',legend=c('points','mean'), 
           col=c('blue', 'red'), pch=c(19, NA), 
           lwd=c(NA, 2), cex=0.7)
  }

}

```

For all of the variables there seems to be outliers towards their upper quantiles. The closest variable to a normal distribution
is the variable 100. Another issue with the data is that is truncated and thus by construction doesn’t have the same domain of a normal
distribution over the random variable.

# Problem 2

## a)
Compute the covariance and correlation matrices for the 7 variables.


Correlation matrix
------------------

```{r,echo=FALSE}

# a) ---------------------------------------------
# calculate matrices
corr_mat=cor(dt[, 2:8]) ; cov_mat=cov(dt[, 2:8]) 
# print correlation mat
# print(corr_mat)
kable(corr_mat,
      caption = "Correlation matrix")

```


Covariance matrix
-----------------

```{r, echo=F}
# print covariance mat
# print(cov_mat)
kable(cov_mat,
      caption = "Covariance matrix")


```


Heatmap
-------

```{r,echo=FALSE}

# Heatmap correlation plot---------------------------------------------
heatmap(cor(dt[,2:8]), Rowv=NA, Colv=NA, revC=TRUE, main="Correlation plot")
```

From the heatmap plot above we can conclude that we have two groups of tracks that are cmore correlated than the others.
One group is formed by the: {100m, 200m and 400} ond the other group from the {800m, 1500m, 3000m and the marathon} variables.

## b)
Illustrate the relations between variables for the 6 pairs: $(x_1 ; x_2 ), (x_2 ; x_3 ), (x_3 ; x_4 ), (x_4 ; x_5 ),
(x_5 ; x_6 ) and (x_6 ; x_7 )$, using scatterplots. Do you observe some extreme values?

Scatterplots
------------


```{r,echo=FALSE}

# b) ---------------------------------------------
par(mfrow=c(3,2), bg='whitesmoke', mar=c(1.9,1.9,1.9,1.9))
for(i in 2:7){
  name1=colnames(dt)[i+1]
  name0=colnames(dt)[i]
  title=paste0(name1," vs ",name0) 
  # print(title)
  plot(dt[, i], dt[, i+1], 
       xlab=colnames(dt)[i], ylab=colnames(dt)[i+1], 
       col='red', pch =19,
       main=paste("Scatterplot ", title))
  lm_model=lm(dt[,i+1]~dt[,i], data=dt)
  abline(lm_model,lty=2, lwd=2)
  }

```

As we can see from the above scatterplots the extreme values are present always on the upper quantiles of each variables. 
Meaning that there are some countries that excels on each category. 

<!-- Moreover, While the lower tracks seem to have a linear dependence to each other, this behaviour vanishes as -->
<!-- the track length of one increases. So a track long track compares to a short track have more like a normal -->
<!-- density around a shifted mean. If both tracks are long, this we see a mixture of these behaviours: Somehow -->
<!-- they cluster up, but still remain some linear dependency (which makes sense to a degree that the track -->
<!-- lenghts actually increase linearly). Also it seems more likely to have outliers for the longer tracks. This can -->
<!-- also be seen in the histograms of the previous exercise. -->

## c)

Which other plotting possibilities for multivariate data you know? Present at least one of them for the given data set. Why did you choose this graph?

Chernoff faces plot
-------------------

```{r, echo=FALSE}
set.seed(13)
ncolors = sample(colors(), 8) 
# Chernoff faces.
faces(dt[, -1], face.type = 1, col.face = rainbow(50)) 

```


The plot above provides a visualization of the data with the Chenoff faces, invented by Herman Chernoff in 1973, and can display multidiensional data in the shape of human face. More specifically, the individual parts of the human face, such as eyes, mouth and nose represent the variables of interest by their shape, size, placement and orientation [[source wikepedia]](https://en.wikipedia.org/wiki/Chernoff_face). 
Chenoff faces as mentioned before can effectively used to represent multidimensional data due to the fact that humans can easily recognoze faces and notice small changes easily.that is why we choose these plots as visualization of the data.

# Problem 3
In problem 2, b) you observed some extreme values. Which countries look the most extreme?
One of the possibilities to answer this question is to compute a distance between an observation and the sample mean vector (to look how far an observation is from the average). Compute the Euclidean distances of observations from the sample mean for all countries. Which 3 countries are the most extreme?

Top 3 most extreme countries
----------------------------

The euclidean distance is defined as :

$$d(\vec{x}, \bar{x})=\sqrt{(\vec{x}-\bar{x})^{T}(\vec{x}-\bar{x})}$$

The distance can be immediately generalized to the $L^r, r>0$ distance as 

$$d_{L^{r}}(\vec{x}, \bar{x})=\left(\sum_{i=1}^{p}\left|\vec{x}_{i}-\bar{x}_{i}\right|^{r}\right)^{1 / r}$$

where $p$ is the dimension of the osbervation (here $p = 7$).
  
Table of extreme countries
--------------------------

```{r,echo=FALSE}

euclidean_dist=function(X){
  X_centered=sweep(X, 2, colMeans(X))
  X_dist=sqrt(diag(X_centered %*% t(X_centered)))
return(X_dist)
}

distances_ed = euclidean_dist(as.matrix(dt[, 2:8]))
idxs = sort(distances_ed, decreasing=TRUE, index.return=TRUE)$ix
countries = dt$country[idxs[1:5]]
countries = as.data.frame(countries)
countries$most_extreme <- 1:nrow(countries)
kable(countries)


```

<!-- From the scatter plots we can see that there are four countries that stand out the most on the 800 meters -->
<!-- track. The countries are SAM, COK, PNG and GUA. These countries are the same ones thata are the most -->
<!-- slow on the feature heatmap and hierarchical cluster presented above. They are considered “extreme” because -->
<!-- they are the slowest countries overall. -->


\newpage

# Appendix 

```{r code=readLines(knitr::purl("/home/quartermaine/Desktop/multivariate_statistical_methods-732A97/labs/Assignment 1/Lab1_report.Rmd",documentation = 1)), echo = T, eval = F}
```









